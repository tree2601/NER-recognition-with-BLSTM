{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Op4Jj99Pv_KI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d3fe05-cc0f-41cb-be39-6d8206467513"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import collections\n",
        "import math\n",
        "import gzip\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device_2 = \"cpu\"\n",
        "path = '/content/drive'\n",
        "drive.mount(path)\n",
        "train_path=  \"/content/drive/My Drive/CSCI544/HW4/hw4/data/train\"\n",
        "dev_path=  \"/content/drive/My Drive/CSCI544/HW4/hw4/data/dev\"\n",
        "test_path=  \"/content/drive/My Drive/CSCI544/HW4/hw4/data/test\"\n",
        "glove_path=  \"/content/drive/My Drive/CSCI544/HW4/hw4/glove.6B.100d.gz\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path) as f:\n",
        "  train = f.read()\n",
        "  train_set = train.split('\\n\\n')\n",
        "train_set = [t.split('\\n') for t in train_set]\n",
        "train_set[-1].pop(-1)\n",
        "\n",
        "\n",
        "with open(dev_path) as f:\n",
        "  dev = f.read()\n",
        "  dev_set = dev.split('\\n\\n')\n",
        "dev_set = [t.split('\\n') for t in dev_set]\n",
        "dev_set[-1].pop(-1)\n",
        "\n",
        "with open(test_path) as f:\n",
        "  test = f.read()\n",
        "  test_set = test.split('\\n\\n')\n",
        "test_set = [t.split('\\n') for t in test_set]\n",
        "test_set[-1].pop(-1)"
      ],
      "metadata": {
        "id": "uiXTeN4awB-9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2ea3efd-f8ed-4254-b709-1dd2b6b50044"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating input data frame:\n",
        "\n",
        "#word index and tag index\n",
        "train_word_set = []\n",
        "for i in range(len(train_set)-1):\n",
        "  train_word_set +=([e.split()[1] for e in train_set[i]])\n",
        "\n",
        "train_word_set += [train_set[-1][0].split()[1]]\n",
        "\n",
        "\n",
        "train_tag_set = []\n",
        "for i in range(len(train_set)-1):\n",
        "  train_tag_set +=([e.split()[2] for e in train_set[i]])\n",
        "train_tag_set += [train_set[-1][0].split()[2]]\n",
        "train_tag_set.append('<PAD>')\n",
        "\n",
        "\n",
        "train_word_set = list(set(train_word_set))\n",
        "train_tag_set = list(set(train_tag_set))\n",
        "train_word_set.append('<UNK>')\n",
        "train_word_set.append('<PAD>')\n",
        "\n",
        "num_tags = len(train_tag_set)\n",
        "num_words = len(train_word_set)\n",
        "\n",
        "idx2word_train = {index:word for  index, word in enumerate(train_word_set)}\n",
        "word2idx_train = {word:index for  index, word in enumerate(train_word_set)}\n",
        "\n",
        "\n",
        "idx2tag_train = {index:tag for  index, tag in enumerate(train_tag_set)}\n",
        "tag2idx_train = {tag:index for  index, tag in enumerate(train_tag_set)}\n",
        "\n",
        "\n",
        "#train\n",
        "for sentence in train_set:\n",
        "  for i in range(len(sentence)):\n",
        "    temp1 = sentence[i].split()[1]\n",
        "    temp2 = sentence[i].split()[2]\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(word2idx_train[temp1])\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(tag2idx_train[temp2])\n",
        "    \n",
        "train_set_reformatted = []\n",
        "for sentence in train_set:\n",
        "  row = []\n",
        "  s = [x.split()[3] for x in sentence]\n",
        "  t = [y.split()[4] for y in sentence]\n",
        "  row.append(s)\n",
        "  row.append(t)\n",
        "  train_set_reformatted.append(row)\n",
        "\n",
        "\n",
        "df_train = pd.DataFrame(train_set_reformatted,columns=['sentence','tag'])\n",
        "vocab_size = len(train_word_set)\n",
        "sentences_train = df_train[\"sentence\"].tolist()\n",
        "tags_train = df_train['tag'].tolist()\n",
        "sentences_train = [[int(num) for num in lst] for lst in sentences_train]\n",
        "tags_train = [[int(num) for num in lst] for lst in tags_train]\n",
        "\n",
        "\n",
        "#dev\n",
        "for sentence in dev_set:\n",
        "  for i in range(len(sentence)):\n",
        "    temp1 = sentence[i].split()[1]\n",
        "    temp2 = sentence[i].split()[2]\n",
        "    sentence[i] +=' '\n",
        "    if temp1 not in word2idx_train:\n",
        "      sentence[i] +=str(word2idx_train['<UNK>'])\n",
        "\n",
        "    else:\n",
        "      sentence[i] +=str(word2idx_train[temp1])\n",
        "\n",
        "    sentence[i] +=' '\n",
        "\n",
        "    sentence[i] +=str(tag2idx_train[temp2])\n",
        "\n",
        "\n",
        "\n",
        "for sentence in test_set:\n",
        "  for i in range(len(sentence)):\n",
        "    temp1 = sentence[i].split()[1]\n",
        "    #temp2 = sentence[i].split()[2]\n",
        "    sentence[i] +=' '\n",
        "    if temp1 not in word2idx_train:\n",
        "      sentence[i] +=str(word2idx_train['<UNK>'])\n",
        "\n",
        "    else:\n",
        "      sentence[i] +=str(word2idx_train[temp1])\n",
        "\n",
        "dev_set_reformatted = []\n",
        "for sentence in dev_set:\n",
        "  row = []\n",
        "  s = [x.split()[3] for x in sentence]\n",
        "  t = [y.split()[4] for y in sentence]\n",
        "  row.append(s)\n",
        "  row.append(t)\n",
        "  dev_set_reformatted.append(row)\n",
        "\n",
        "\n",
        "df_dev = pd.DataFrame(dev_set_reformatted,columns=['sentence','tag'])\n",
        "sentences_dev = df_dev[\"sentence\"].tolist()\n",
        "tags_dev = df_dev['tag'].tolist()\n",
        "sentences_dev = [[int(num) for num in lst] for lst in sentences_dev]\n",
        "tags_dev = [[int(num) for num in lst] for lst in tags_dev]\n",
        "\n",
        "#test\n",
        "test_set_reformatted = []\n",
        "for sentence in test_set:\n",
        "  row = []\n",
        "  s = [x.split()[2] for x in sentence]\n",
        "  #t = [y.split()[4] for y in sentence]\n",
        "  #row.append(s)\n",
        "  #row.append(t)\n",
        "  test_set_reformatted.append(s)\n",
        "\n",
        "\n",
        "df_test = pd.DataFrame({'sentence': test_set_reformatted})\n",
        "sentences_test = df_test[\"sentence\"].tolist()\n",
        "sentences_test = [[int(num) for num in lst] for lst in sentences_test]\n",
        "\n",
        "\n",
        "\n",
        "padded_sentences_train = pad_sequence([torch.tensor(s) for s in sentences_train], batch_first=True,padding_value=word2idx_train['<PAD>'])\n",
        "padded_tags_train = pad_sequence([torch.tensor(t) for t in tags_train], batch_first=True, padding_value=tag2idx_train['<PAD>'])\n",
        "padded_sentences_dev = pad_sequence([torch.tensor(s) for s in sentences_dev], batch_first=True,padding_value=word2idx_train['<PAD>'])\n",
        "padded_tags_dev = pad_sequence([torch.tensor(t) for t in tags_dev], batch_first=True, padding_value=tag2idx_train['<PAD>'])"
      ],
      "metadata": {
        "id": "tUPevBObwCBA"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------Task 1-----------------------------"
      ],
      "metadata": {
        "id": "dVZE-ND7a3LG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "lstm_layers = 1\n",
        "lstm_hidden_dim = 256\n",
        "lstm_dropout = 0.33\n",
        "linear_output_dim = 128\n",
        "learning_rate = 0.2\n",
        "num_epochs = 150\n",
        "batch_size = 32\n",
        "alpha = 5\n",
        "\n",
        "class BLSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim, lstm_layers, lstm_hidden_dim, lstm_dropout, linear_output_dim,alpha):\n",
        "        super(BLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers, dropout=lstm_dropout, bidirectional=True,batch_first=True)\n",
        "        self.linear = nn.Linear(in_features=lstm_hidden_dim*2, out_features=linear_output_dim)\n",
        "        self.activation = nn.ELU(alpha= alpha)\n",
        "        self.dropout = nn.Dropout(lstm_dropout)\n",
        "        self.classifier = nn.Linear(in_features=linear_output_dim, out_features=num_tags)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        linear_out = self.dropout(lstm_out)\n",
        "        linear_out = self.linear(linear_out)\n",
        "      \n",
        "        activation_out = self.activation(linear_out)\n",
        "        classifier_out = self.classifier(activation_out)\n",
        "        return classifier_out\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, tags):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence = self.sentences[index]\n",
        "        tag = self.tags[index]\n",
        "        \n",
        "        sentence_tensor = torch.tensor(sentence, dtype=torch.long)\n",
        "        tag_tensor = torch.tensor(tag, dtype=torch.long)\n",
        "\n",
        "        return sentence_tensor, tag_tensor"
      ],
      "metadata": {
        "id": "ZRyjBMU8kvpV"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NERDataset(padded_sentences_train,padded_tags_train)\n",
        "val_dataset = NERDataset(padded_sentences_dev,padded_tags_dev)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "model = BLSTM(embedding_dim, lstm_layers, lstm_hidden_dim, lstm_dropout, linear_output_dim,alpha)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag2idx_train['<PAD>'])\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.8)\n",
        "model.to(device)\n",
        "#model.to(device_2)"
      ],
      "metadata": {
        "id": "W7VwXeS0qTNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model.train()\n",
        "    for sentences, tags in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sentences = sentences.to(device)\n",
        "        tags = tags.to(device)\n",
        "        outputs = model(sentences)\n",
        "        #mask = (tags != tag2idx_train['<PAD>']).float()\n",
        "        loss = criterion(outputs.view(-1, num_tags), tags.view(-1))\n",
        "        #loss = (loss * mask.view(-1)).sum() /mask.sum()\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    \n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss/len(train_loader)))\n"
      ],
      "metadata": {
        "id": "9ADUxsvk1zyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate test result\n",
        "print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss/len(train_loader)))\n",
        "test_pred_result = []\n",
        "model.eval()\n",
        "for s in sentences_test:\n",
        "  test_tensor = torch.tensor(s).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(test_tensor)\n",
        "    outputs = outputs.cpu().numpy()\n",
        "    predicted_tags = np.argmax(outputs, axis=1)\n",
        "    test_pred_result.append(list(predicted_tags)) \n",
        "\n",
        "\n",
        "with open('test_prediction.txt', 'w') as f:\n",
        "  for i in range(df_test.shape[0]):\n",
        "    s_pred = test_pred_result[i]\n",
        "    \n",
        "    l = len(s_pred)\n",
        "    ss = sentences_test[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_train[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_pred[j]]}\\n')\n",
        "\n",
        "    if i!=df_test.shape[0]-1:\n",
        "      f.write('\\n')\n",
        "\n",
        "\n",
        "with open('test1.out', 'w') as f:\n",
        "  for i in range(df_test.shape[0]):\n",
        "    s_pred = test_pred_result[i]\n",
        "    \n",
        "    l = len(s_pred)\n",
        "    ss = sentences_test[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_train[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_pred[j]]}\\n')\n",
        "    if i!=df_test.shape[0]-1:\n",
        "      f.write('\\n')    \n",
        "\n",
        "#generate dev result\n",
        "dev_pred_result = []\n",
        "model.eval()\n",
        "for s in sentences_dev:\n",
        "  dev_tensor = torch.tensor(s).to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(dev_tensor)\n",
        "    outputs = outputs.cpu().numpy()\n",
        "    predicted_tags = np.argmax(outputs, axis=1)\n",
        "    dev_pred_result.append(list(predicted_tags))\n",
        "   \n",
        "\n",
        "with open('dev_prediction.txt', 'w') as f:\n",
        "  for i in range(df_dev.shape[0]):\n",
        "    s_pred = dev_pred_result[i]\n",
        "    s_true = tags_dev[i]\n",
        "    l = len(s_pred)\n",
        "    ss = sentences_dev[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_train[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_true[j]]} {idx2tag_train[s_pred[j]]}\\n')\n",
        "    if i!=df_dev.shape[0]-1:\n",
        "      f.write('\\n')\n",
        "\n",
        "\n",
        "with open('dev1.out', 'w') as f:\n",
        "  for i in range(df_dev.shape[0]):\n",
        "    s_pred = dev_pred_result[i]\n",
        "    l = len(s_pred)\n",
        "    ss = sentences_dev[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_train[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_pred[j]]}\\n')\n",
        "    if i!=df_dev.shape[0]-1:\n",
        "      f.write('\\n')\n",
        "    "
      ],
      "metadata": {
        "id": "04imC_wKPT-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5388dd1-b71f-403f-f360-a863211cc4db"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [150/150], Train Loss: 0.0138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model and results for task 1\n",
        "model_state_dict = model.state_dict()\n",
        "model_path = 'blstm1.pt'\n",
        "torch.save(model_state_dict, model_path)\n",
        "files.download('blstm1.pt') \n",
        "\n",
        "files.download('test_prediction.txt') \n",
        "files.download('dev_prediction.txt') \n",
        "files.download('dev1.out')\n",
        "files.download('test1.out')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "520UM5R_jqO3",
        "outputId": "f038a2b0-8d91-4d62-fc30-d2ac09f46524"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a071f379-0487-4706-8836-a58593c6331e\", \"blstm1.pt\", 12653583)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f8238d3-7e5d-4352-9bfb-e7073c766385\", \"test_prediction.txt\", 474050)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e16743d0-22c8-451c-9c8b-5b2970749bba\", \"dev_prediction.txt\", 671574)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3097e199-d4a0-4184-bba4-e762b30501e2\", \"dev_1.out\", 532738)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be724d4c-952a-4f4e-a866-5783cc2c25ff\", \"test_1.out\", 474050)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------Task 2----------------------------"
      ],
      "metadata": {
        "id": "V8WZcxMlQrrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(train_path) as f:\n",
        "  train = f.read()\n",
        "  train_set = train.split('\\n\\n')\n",
        "train_set = [t.split('\\n') for t in train_set]\n",
        "train_set[-1].pop(-1)\n",
        "\n",
        "\n",
        "with open(dev_path) as f:\n",
        "  dev = f.read()\n",
        "  dev_set = dev.split('\\n\\n')\n",
        "dev_set = [t.split('\\n') for t in dev_set]\n",
        "dev_set[-1].pop(-1)\n",
        "\n",
        "with open(test_path) as f:\n",
        "  test = f.read()\n",
        "  test_set = test.split('\\n\\n')\n",
        "test_set = [t.split('\\n') for t in test_set]\n",
        "test_set[-1].pop(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I7sVTqwjY-8N",
        "outputId": "000964ee-d55d-4941-f7a2-a69dd47e7681"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading glove\n",
        "embeddings = []\n",
        "glove_words=[]\n",
        "\n",
        "#processing glove\n",
        "with gzip.open(glove_path, 'rt') as f:\n",
        "  for line in f:\n",
        "    line = line.strip()\n",
        "    parts = line.split()\n",
        "    word = parts[0]\n",
        "    glove_words.append(word)\n",
        "    embedding = np.array([float(p) for p in parts[1:]])\n",
        "    embeddings.append(embedding)\n"
      ],
      "metadata": {
        "id": "Q_LOxgUqa2R8"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = torch.tensor(embeddings)\n",
        "glove_words = [\"<PAD>\",\"<UNK>\"] + glove_words\n",
        "pad_vec = torch.zeros(1, 100)\n",
        "unk_vec = torch.randn(1, 100)\n",
        "glove_vectors = torch.cat([pad_vec, unk_vec, embeddings], dim=0)\n",
        "word2idx_glove = {word: idx for idx, word in enumerate(glove_words)}\n",
        "idx2word_glove = {idx: word for idx, word in enumerate(glove_words)}\n",
        "num_words = len(glove_words)\n",
        "\n",
        "\n",
        "tag2idx_train['<PAD>'],tag2idx_train['B-LOC']=tag2idx_train['B-LOC'],tag2idx_train['<PAD>']\n",
        "num_tags = len(tag2idx_train)\n",
        "\n",
        "\n",
        "def is_capital(word):\n",
        "  return int(word != word.lower()) +1"
      ],
      "metadata": {
        "id": "OhDAfsghkOdk"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train task2\n",
        "\n",
        "for sentence in train_set:\n",
        "  for i in range(len(sentence)):\n",
        "    temp1 = sentence[i].split()[1]\n",
        "    temp2 = sentence[i].split()[2]\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(word2idx_glove[temp1.lower()]) if temp1.lower() in word2idx_glove else str(word2idx_glove['<UNK>'])\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(tag2idx_train[temp2])\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(is_capital(temp1))\n",
        "    \n",
        "train_set_reformatted = []\n",
        "for sentence in train_set:\n",
        "  row = []\n",
        "  s = [x.split()[3] for x in sentence]\n",
        "  t = [y.split()[4] for y in sentence]\n",
        "  c = [z.split()[5] for z in sentence]\n",
        "  row.append(s)\n",
        "  row.append(t)\n",
        "  row.append(c)\n",
        "  train_set_reformatted.append(row)\n",
        "\n",
        "df_train = pd.DataFrame(train_set_reformatted,columns=['sentence','tag','cap'])\n",
        "sentences_train = df_train[\"sentence\"].tolist()\n",
        "tags_train = df_train['tag'].tolist()\n",
        "caps_train = df_train['cap'].tolist()\n",
        "sentences_train = [[int(num) for num in lst] for lst in sentences_train]\n",
        "tags_train = [[int(num) for num in lst] for lst in tags_train]\n",
        "caps_train = [[int(num) for num in lst] for lst in caps_train]\n",
        "\n",
        "\n",
        "\n",
        "#dev task2\n",
        "for sentence in dev_set:\n",
        "  for i in range(len(sentence)):\n",
        "    temp1 = sentence[i].split()[1]\n",
        "    temp2 = sentence[i].split()[2]\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(word2idx_glove[temp1.lower()]) if temp1.lower() in word2idx_glove else str(word2idx_glove['<UNK>'])\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(tag2idx_train[temp2])\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(is_capital(temp1))\n",
        "\n",
        "\n",
        "dev_set_reformatted = []\n",
        "for sentence in dev_set:\n",
        "  row = []\n",
        "  s = [x.split()[3] for x in sentence]\n",
        "  t = [y.split()[4] for y in sentence]\n",
        "  c = [z.split()[5] for z in sentence]\n",
        "  row.append(s)\n",
        "  row.append(t)\n",
        "  row.append(c)\n",
        "  dev_set_reformatted.append(row)\n",
        "\n",
        "\n",
        "df_dev = pd.DataFrame(dev_set_reformatted,columns=['sentence','tag','cap'])\n",
        "sentences_dev = df_dev[\"sentence\"].tolist()\n",
        "tags_dev = df_dev['tag'].tolist()\n",
        "caps_dev = df_dev['cap'].tolist()\n",
        "sentences_dev = [[int(num) for num in lst] for lst in sentences_dev]\n",
        "tags_dev = [[int(num) for num in lst] for lst in tags_dev]\n",
        "caps_dev = [[int(num) for num in lst] for lst in caps_dev]\n",
        "\n",
        "\n",
        "#test task2\n",
        "for sentence in test_set:\n",
        "  for i in range(len(sentence)):\n",
        "    temp1 = sentence[i].split()[1]\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(word2idx_glove[temp1.lower()]) if temp1.lower() in word2idx_glove else str(word2idx_glove['<UNK>'])\n",
        "    sentence[i] +=' '\n",
        "    sentence[i] +=str(is_capital(temp1))\n",
        "\n",
        "\n",
        "test_set_reformatted = []\n",
        "for sentence in test_set:\n",
        "  row = []\n",
        "  s = [x.split()[2] for x in sentence]\n",
        "  c = [z.split()[3] for z in sentence]\n",
        "  row.append(s)\n",
        "  row.append(c)\n",
        "  test_set_reformatted.append(row)\n",
        "\n",
        "\n",
        "df_test = pd.DataFrame(test_set_reformatted,columns=['sentence','cap'])\n",
        "sentences_test = df_test[\"sentence\"].tolist()\n",
        "caps_test = df_test['cap'].tolist()\n",
        "sentences_test = [[int(num) for num in lst] for lst in sentences_test]\n",
        "caps_test = [[int(num) for num in lst] for lst in caps_test]\n"
      ],
      "metadata": {
        "id": "f17w3WYm3r_W"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "lstm_layers = 1\n",
        "lstm_hidden_dim = 256\n",
        "lstm_dropout = 0.33\n",
        "linear_output_dim = 128\n",
        "learning_rate = 0.2\n",
        "num_epochs = 50\n",
        "batch_size = 32\n",
        "alpha = 5\n",
        "\n",
        "\n",
        "class BLSTM_glove(nn.Module):\n",
        "    def __init__(self, embedding_dim, lstm_layers, lstm_hidden_dim, lstm_dropout, linear_output_dim,alpha):\n",
        "        super(BLSTM_glove, self).__init__()\n",
        "        \n",
        "       \n",
        "        self.embedding = nn.Embedding.from_pretrained(glove_vectors, freeze=True)\n",
        "        self.capital_embedding = nn.Embedding(3, embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=lstm_hidden_dim, num_layers=lstm_layers, bidirectional=True,batch_first=True)\n",
        "        self.linear = nn.Linear(in_features=lstm_hidden_dim*2, out_features=linear_output_dim)\n",
        "        self.dropout = nn.Dropout(lstm_dropout)\n",
        "        self.activation = nn.ELU(alpha= alpha)\n",
        "        self.classifier = nn.Linear(in_features=linear_output_dim, out_features=num_tags)\n",
        "\n",
        "    def forward(self,x,capital_x):\n",
        "        \n",
        "        embedded = self.embedding(x)\n",
        "        capital_embedded = self.capital_embedding(capital_x)\n",
        "        capital_embedded= capital_embedded.float()\n",
        "        embedded = embedded.float()\n",
        "        lstm_out, _ = self.lstm(embedded+capital_embedded)\n",
        "        linear_out = self.dropout(lstm_out)\n",
        "        linear_out = self.linear(linear_out)\n",
        "        activation_out = self.activation(linear_out)\n",
        "        classifier_out = self.classifier(activation_out)\n",
        "        return classifier_out\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, tags,caps):\n",
        "        self.sentences = sentences\n",
        "        self.tags = tags\n",
        "        self.caps = caps\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence = self.sentences[index]\n",
        "        tag = self.tags[index]\n",
        "        cap = self.caps[index]\n",
        "        sentence_tensor = torch.tensor(sentence, dtype=torch.long)\n",
        "        tag_tensor = torch.tensor(tag,dtype = torch.long)\n",
        "        cap_tensor = torch.tensor(cap,dtype = torch.long)\n",
        "\n",
        "        return sentence_tensor,tag_tensor,cap_tensor\n",
        "\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    padded_sentences = pad_sequence([b[0] for b in batch], batch_first=True, padding_value=word2idx_glove['<PAD>'])\n",
        "    padded_tags = pad_sequence([b[1] for b in batch], batch_first=True, padding_value=tag2idx_train['<PAD>'])\n",
        "    padded_caps = pad_sequence([b[2] for b in batch], batch_first=True, padding_value=0)\n",
        "\n",
        "    return padded_sentences, padded_tags, padded_caps"
      ],
      "metadata": {
        "id": "5xMVNcdEbc-l"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train_sentences, val_sentences, train_tags, val_tags = train_test_split(sentences_train, tags_train, test_size=0.2)\n",
        "train_dataset = NERDataset(sentences_train,tags_train,caps_train)\n",
        "dev_dataset = NERDataset(sentences_dev,tags_dev,caps_dev)\n",
        "train_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=32)\n",
        "val_loader = DataLoader(dev_dataset, collate_fn=collate_fn, batch_size=32)\n",
        "\n",
        "model_2 = BLSTM_glove(embedding_dim, lstm_layers, lstm_hidden_dim, lstm_dropout, linear_output_dim,alpha)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tag2idx_train['<PAD>'])\n",
        "optimizer = optim.SGD(model_2.parameters(), lr=learning_rate)\n",
        "scheduler = StepLR(optimizer, step_size=20, gamma=0.8)\n",
        "model_2.to(device)\n",
        "#model.to(device_2)"
      ],
      "metadata": {
        "id": "DBKdeBAHg-34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fe28e9-4724-4182-8083-1ecf6b04ffeb"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BLSTM_glove(\n",
              "  (embedding): Embedding(400002, 100)\n",
              "  (capital_embedding): Embedding(3, 100)\n",
              "  (lstm): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
              "  (linear): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (dropout): Dropout(p=0.33, inplace=False)\n",
              "  (activation): ELU(alpha=5)\n",
              "  (classifier): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    model_2.train()\n",
        "    for sentences, tags,capital in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        sentences = sentences.to(device)\n",
        "        tags = tags.to(device)\n",
        "        capitals = capital.to(device)\n",
        "\n",
        "        outputs = model_2(sentences, capitals)\n",
        "        #mask = (tags != tag2idx_train['<PAD>']).float()\n",
        "        loss = criterion(outputs.view(-1, num_tags), tags.view(-1))\n",
        "        #loss = (loss * mask.view(-1)).sum() /mask.sum()\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    \n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss/len(train_loader)))\n"
      ],
      "metadata": {
        "id": "xB7jwRSyhfBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate test result\n",
        "print('Epoch [{}/{}], Train Loss: {:.4f}'.format(epoch+1, num_epochs, train_loss/len(train_loader)))\n",
        "test_pred_result = []\n",
        "model_2.eval()\n",
        "for i in range(len(sentences_test)):\n",
        "  sentence_test_tensor = torch.tensor(sentences_test[i]).to(device)\n",
        "  \n",
        "  capital_test_tensor = torch.tensor(caps_test[i]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model_2(sentence_test_tensor,capital_test_tensor)\n",
        "    outputs = outputs.cpu().numpy()\n",
        "    predicted_tags = np.argmax(outputs, axis=1)\n",
        "    test_pred_result.append(list(predicted_tags))\n",
        "   \n",
        "\n",
        "\n",
        "with open('test_prediction_2.txt', 'w') as f:\n",
        "  for i in range(df_test.shape[0]):\n",
        "    s_pred = test_pred_result[i]\n",
        "    \n",
        "    l = len(s_pred)\n",
        "    ss = sentences_test[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_glove[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_pred[j]]}\\n')\n",
        "      \n",
        "    if i!=df_test.shape[0]-1:\n",
        "      f.write('\\n')\n",
        "\n",
        "\n",
        "with open('test2.out', 'w') as f:\n",
        "  for i in range(df_test.shape[0]):\n",
        "    s_pred = test_pred_result[i]\n",
        "    \n",
        "    l = len(s_pred)\n",
        "    ss = sentences_test[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_glove[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_pred[j]]}\\n')\n",
        "    if i!=df_test.shape[0]-1:\n",
        "      f.write('\\n')    \n",
        " \n",
        "\n",
        "\n",
        "#generate dev result\n",
        "dev_pred_result = []\n",
        "model_2.eval()\n",
        "for i in range(len(sentences_dev)):\n",
        "  sentence_dev_tensor = torch.tensor(sentences_dev[i]).to(device)\n",
        "  \n",
        "  capital_tensor_dev = torch.tensor(caps_dev[i]).to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model_2(sentence_dev_tensor,capital_tensor_dev)\n",
        "    outputs = outputs.cpu().numpy()\n",
        "    predicted_tags = np.argmax(outputs, axis=1)\n",
        "    dev_pred_result.append(list(predicted_tags))\n",
        "    \n",
        "\n",
        "with open('dev_prediction_2.txt', 'w') as f:\n",
        "  for i in range(df_dev.shape[0]):\n",
        "    s_pred = dev_pred_result[i]\n",
        "    s_true = tags_dev[i]\n",
        "    l = len(s_pred)\n",
        "    ss = sentences_dev[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_glove[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_true[j]]} {idx2tag_train[s_pred[j]]}\\n')\n",
        "    if i!=df_dev.shape[0]-1:\n",
        "      f.write('\\n')\n",
        "\n",
        "\n",
        "with open('dev2.out', 'w') as f:\n",
        "  for i in range(df_dev.shape[0]):\n",
        "    s_pred = dev_pred_result[i]\n",
        "    l = len(s_pred)\n",
        "    ss = sentences_dev[i]\n",
        "    for j in range(l):\n",
        "      word =idx2word_glove[ss[j]]\n",
        "      f.write(f'{j+1} {word} {idx2tag_train[s_pred[j]]}\\n')\n",
        "    if i!=df_dev.shape[0]-1:\n",
        "      f.write('\\n')\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEYgc332iDDs",
        "outputId": "eee28d5e-9825-4045-847c-95ce3204abbe"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [80/80], Train Loss: 0.0180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model and results for task 2\n",
        "model_state_dict_2 = model_2.state_dict()\n",
        "model_path = 'blstm2.pt'\n",
        "torch.save(model_state_dict_2, model_path)\n",
        "files.download('blstm2.pt') \n",
        "\n",
        "files.download('test_prediction_2.txt') \n",
        "files.download('dev_prediction_2.txt') \n",
        "files.download('dev2.out')\n",
        "files.download('test2.out')"
      ],
      "metadata": {
        "id": "oMQXkINZSe55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3e17dc31-ad7b-4c75-9820-c78bd92a783c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_35b2b734-8ab4-40ef-a96b-18b712a457ba\", \"blstm2.pt\", 323206218)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3e9c6e9-a5f9-4dc8-9643-9f5d8c39eddf\", \"test_prediction_2.txt\", 491803)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9fc23e0b-85c9-4493-8058-2ecebf7a1efe\", \"dev_prediction_2.txt\", 686201)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af345fd0-50d8-437f-b496-bbd044869bbe\", \"dev_2.out\", 547365)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_709dd6f5-40a5-4e2d-8762-8457e60e46e7\", \"test_2.out\", 491803)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}